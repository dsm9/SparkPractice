{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Massive Data Processing\n",
    "\n",
    "## Spark practice\n",
    "\n",
    "<b>Student: David SÃ¡nchez</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "sc = pyspark.SparkContext('local[*]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.-Practice: Trending Topics & analysis sentiment (5.0%)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trending Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. partitions:  6\n",
      "Total tweets:  19166\n",
      "Spanish tweets:  15028\n",
      "Tweets with hashtags:  3495\n",
      "Hashtags:  5286\n",
      "Hashtags reduced:  2947\n",
      "Files saved: '../Results/Trending'\n",
      "Some examples:  [('VineDeLaAbuela', 1), ('', 1), ('RMUCL', 11), ('PorSiNoLoViste', 2), ('industria40', 1), ('wallapop', 1), ('ConMaduroAvanzamos', 3), ('DisenoGrafico', 1), ('candycrush', 1), ('ElClasico', 1)]\n"
     ]
    }
   ],
   "source": [
    "import os, shutil\n",
    "import json\n",
    "import unicodedata\n",
    "from operator import add\n",
    "\n",
    "numPartitions = 6\n",
    "input = sc.textFile(\"../Datasets/Tweets/tweets_es.json\", numPartitions)\n",
    "tweets = input.map(lambda x: json.loads(x))\n",
    "print \"Num. partitions: \", tweets.getNumPartitions()\n",
    "print \"Total tweets: \", tweets.count()\n",
    "\n",
    "tweets_es = tweets.filter(lambda t: \"es\" in t[\"lang\"])\n",
    "print \"Spanish tweets: \", tweets_es.count()\n",
    "\n",
    "tweets_es_hashtags = tweets_es.filter(lambda t: t[\"entities\"][\"hashtags\"] != [] )\n",
    "        \n",
    "print  \"Tweets with hashtags: \", tweets_es_hashtags.count()\n",
    "\n",
    "hashtags = tweets_es_hashtags.flatMap(lambda t: map(lambda h: (unicodedata.normalize('NFKD', h[\"text\"]).encode('ascii','ignore'),1), t[\"entities\"][\"hashtags\"]))\n",
    "print \"Hashtags: \", hashtags.count()\n",
    "\n",
    "trending_hashtags = hashtags.reduceByKey(lambda a, b: a + b)\n",
    "print \"Hashtags reduced: \", trending_hashtags.count()\n",
    "\n",
    "if os.path.exists(\"../Results/Trending\"): \n",
    "    shutil.rmtree(\"../Results/Trending\")\n",
    "trending_hashtags.saveAsTextFile('../Results/Trending')\n",
    "print \"Files saved: '../Results/Trending'\"\n",
    "print \"Some examples: \", trending_hashtags.take(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('MTVMiaw', 196), ('Vota2ParaQueSigaPresidente', 117), ('FelizMartes', 84), ('TuitUtil', 65), ('LibertadDePrensa', 64), ('TeCaesTeLevantasFelices27Mica', 51), ('MTVSnapMexDanna', 39), ('MTVPopMBautista', 37), ('MtvIconoMBautista', 34), ('DebateReal', 34)]\n",
      "Files saved: '../Results/TopN'\n"
     ]
    }
   ],
   "source": [
    "trending_sorted = trending_hashtags.takeOrdered(10, key=lambda t: -t[1])\n",
    "print trending_sorted\n",
    "\n",
    "if os.path.exists(\"../Results/TopN\"): \n",
    "    shutil.rmtree(\"../Results/TopN\")\n",
    "sc.parallelize(trending_sorted).saveAsTextFile('../Results/TopN')\n",
    "print \"Files saved: '../Results/TopN'\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive and negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive words:  ['libera', 'como', 'gran', 'mayor', 'nuevo', 'general', 'obra', 'principal', 'bien', 'poco'] ...\n",
      "Negative words:  ['divisas', 'en', 'para', 'sin', 'tiempo', 'bajo', 'varios', 'tipo', 'largo', 'solo'] ...\n"
     ]
    }
   ],
   "source": [
    "file_positive = sc.textFile(\"../Dictionary/positive_words_es.txt\")\n",
    "file_negative = sc.textFile(\"../Dictionary/negative_words_es.txt\")\n",
    "positive_words = file_positive.map(lambda w: w.encode('ascii', 'ignore'))\n",
    "negative_words = file_negative.map(lambda w: w.encode('ascii', 'ignore'))\n",
    "positive_words_list = positive_words.collect()\n",
    "negative_words_list = negative_words.collect()\n",
    "\n",
    "print \"Positive words: \", positive_words.take(10), \"...\"\n",
    "print \"Negative words: \", negative_words.take(10), \"...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('@disneyspain @tinistoessel libera logooo \\n#tini', 'tini'), ('rt @amctv_es: el grupo esta separado... conseguiran escapar? llegaran a baja? el proximo lunes nuevo episodio! #feartwd\\nhttps://t.co/vqw...', 'feartwd')]\n"
     ]
    }
   ],
   "source": [
    "tweets_hashtags = tweets_es_hashtags.map(lambda t: (unicodedata.normalize('NFKD',t[\"text\"]).encode('ascii','ignore').lower(),\\\n",
    "                                                (map(lambda h: unicodedata.normalize('NFKD',h[\"text\"]).encode('ascii','ignore').lower(), \\\n",
    "                                                     t[\"entities\"][\"hashtags\"]))))\\\n",
    "                                                .flatMapValues(lambda x: x)\n",
    "print tweets_hashtags.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HashtagSentiment(tweet):\n",
    "    \n",
    "    positive_count = 0\n",
    "    negative_count = 0\n",
    "    hashtag = tweet[1]\n",
    "    words = tweet[0].split(\" \")\n",
    "    length = len(words)\n",
    "    for word in words:\n",
    "        if word in positive_words_list:\n",
    "            positive_count += 1\n",
    "        elif word in negative_words_list:\n",
    "            negative_count += 1\n",
    "    \n",
    "    return (hashtag, (length, positive_count, negative_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasghtag base sentiment info: \n",
      "[('', (14, 0, 0)), ('mtvmatchcastel', (14, 0, 0)), ('barranquilla', (10, 0, 0)), ('asslickers', (15, 1, 1)), ('industria40', (17, 0, 1)), ('mamafrigilux', (21, 0, 2)), ('afterclasswqradio', (12, 0, 1)), ('wallapop', (9, 0, 1)), ('luchojara', (18, 1, 2)), ('bautisters', (19, 2, 0))]\n"
     ]
    }
   ],
   "source": [
    "hashtags_base_sentim = tweets_hashtags.map(lambda t: HashtagSentiment(t))\\\n",
    "                .reduceByKey(lambda a, b:(a[0]+b[0], a[1]+b[1], a[2]+b[2]))\n",
    "print \"Hasghtag base sentiment info: \"\n",
    "print hashtags_base_sentim.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hashtag sentiments: \n",
      "[('', 0.0), ('mtvmatchcastel', 0.0), ('barranquilla', 0.0), ('asslickers', 0.0), ('industria40', -0.058823529411764705), ('mamafrigilux', -0.09523809523809523), ('afterclasswqradio', -0.08333333333333333), ('wallapop', -0.1111111111111111), ('luchojara', -0.05555555555555555), ('bautisters', 0.10526315789473684)]\n"
     ]
    }
   ],
   "source": [
    "hashtags_sentim = hashtags_base_sentim.map(lambda h: (h[0],float(h[1][1]-h[1][2])/h[1][0]))\n",
    "print \"Hashtag sentiments: \"\n",
    "print hashtags_sentim.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
